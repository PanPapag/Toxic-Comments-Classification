{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     /Users/pantelis/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pantelis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/pantelis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/pantelis/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Ignoring unnecessory warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "# Specialized container datatypes\n",
    "import collections\n",
    "# For data vizualization \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# For large and multi-dimensional arrays\n",
    "import numpy as np\n",
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "# Natural language processing library\n",
    "import nltk\n",
    "nltk.download('genesis')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# For random selection \n",
    "import random\n",
    "# For basic cleaning and data preprocessing \n",
    "import re\n",
    "import string\n",
    "# Machine Learning Library\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's load our train set to pandas dataframe for ease in data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3947 entries, 0 to 3946\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Insult   3947 non-null   int64 \n",
      " 1   Date     3229 non-null   object\n",
      " 2   Comment  3947 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 92.6+ KB\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET = \"./data/train.csv\"\n",
    "train_df = pd.read_csv(TRAIN_DATASET, encoding='utf-8')\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's have a look at the very first 5 rows of our train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult             Date                                            Comment\n",
       "0       1  20120618192155Z                               \"You fuck your dad.\"\n",
       "1       0  20120528192215Z  \"i really don't understand your point.\\xa0 It ...\n",
       "2       0              NaN  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3       0              NaN  \"listen if you dont wanna get married to a man...\n",
       "4       0  20120619094753Z  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate our trained models, we are going to use a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2235 entries, 0 to 2234\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       2235 non-null   int64 \n",
      " 1   Insult   2235 non-null   int64 \n",
      " 2   Date     2235 non-null   object\n",
      " 3   Comment  2235 non-null   object\n",
      " 4   Usage    2235 non-null   object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 87.4+ KB\n"
     ]
    }
   ],
   "source": [
    "TEST_DATASET = \"./data/impermium_verification_labels.csv\"\n",
    "test_df = pd.read_csv(TEST_DATASET)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Insult             Date  \\\n",
       "0   1       0  20120603163526Z   \n",
       "1   2       1  20120531215447Z   \n",
       "2   3       1  20120823164228Z   \n",
       "3   4       1  20120826010752Z   \n",
       "4   5       1  20120602223825Z   \n",
       "\n",
       "                                             Comment        Usage  \n",
       "0                 \"like this if you are a tribe fan\"  PrivateTest  \n",
       "1              \"you're idiot.......................\"  PrivateTest  \n",
       "2  \"I am a woman Babs, and the only \"war on women...  PrivateTest  \n",
       "3  \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...  PrivateTest  \n",
       "4  \"haha green me red you now loser whos winning ...  PrivateTest  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common to train our models when our data has already being cleaned and preproccessed. Data cleaning is a crucial step and of utter importance when it comes to training machine learning models that aim at high metrics score. The basic data cleaning steps that we are going to apply are:\n",
    "1. Remove unnecessary columns\n",
    "2. Drop rows with NaN values\n",
    "3. Convert all characters to lowercase\n",
    "4. Remove characters such as punctuation, characters such as \"\\ n\", \"\\ u0111\"\n",
    "5. Remove urls if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # remove all special characters, punctuation and spaces from string\n",
    "    text = re.sub(r'\\W+',' ', text)\n",
    "    # remove urls if any\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    # remove non ascii characters\n",
    "    text = re.sub(r'(x[(a|c|e|f)|(0-9)]+|(u[(0-9)]+))', '', text)\n",
    "    # return cleaned text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's perform data cleaning in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "0          1                               \"You fuck your dad.\"\n",
       "1          0  \"i really don't understand your point.\\xa0 It ...\n",
       "2          0  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...\n",
       "3          0  \"listen if you dont wanna get married to a man...\n",
       "4          0  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...\n",
       "...      ...                                                ...\n",
       "3942       1  \"you are both morons and that is never happening\"\n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...\n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...\n",
       "3945       0  \"How about Felix? He is sure turning into one ...\n",
       "3946       0  \"You're all upset, defending this hipster band...\n",
       "\n",
       "[3947 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Date column\n",
    "train_df.drop(['Date'], axis=1, inplace=True)\n",
    "# Drop any NaN value\n",
    "train_df.dropna(inplace=True)\n",
    "# Rest index \n",
    "train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Comment section\n",
    "train_df['Comment'] = train_df['Comment'].apply(lambda x: data_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>i really don t understand your point  it seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a  majority of canadians can and has been wro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>c  b ea1n xu ed1ng  b0 eddng bi ec3u t nh 201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult                                            Comment\n",
       "0       1                                 you fuck your dad \n",
       "1       0   i really don t understand your point  it seem...\n",
       "2       0   a  majority of canadians can and has been wro...\n",
       "3       0   listen if you dont wanna get married to a man...\n",
       "4       0   c  b ea1n xu ed1ng  b0 eddng bi ec3u t nh 201..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that train set is way more cleaned now. Let's perform the same procedure for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0</td>\n",
       "      <td>\"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>1</td>\n",
       "      <td>\"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0</td>\n",
       "      <td>\"sweetie pie is looking very much like her cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>1</td>\n",
       "      <td>\"ball4real where are you with your miami g-ayn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Man....if you are a 3 point shooter, you must...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment\n",
       "0          0                 \"like this if you are a tribe fan\"\n",
       "1          1              \"you're idiot.......................\"\n",
       "2          1  \"I am a woman Babs, and the only \"war on women...\n",
       "3          1  \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...\n",
       "4          1  \"haha green me red you now loser whos winning ...\n",
       "...      ...                                                ...\n",
       "2230       0  \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...\n",
       "2231       1  \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...\n",
       "2232       0  \"sweetie pie is looking very much like her cou...\n",
       "2233       1  \"ball4real where are you with your miami g-ayn...\n",
       "2234       0  \"Man....if you are a 3 point shooter, you must...\n",
       "\n",
       "[2235 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Date column\n",
    "test_df.drop(['id', 'Date', 'Usage'], axis=1, inplace=True)\n",
    "# Drop any NaN value\n",
    "test_df.dropna(inplace=True)\n",
    "# Rest index \n",
    "test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Comment section\n",
    "test_df['Comment'] = test_df['Comment'].apply(lambda x: data_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>like this if you are a tribe fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>you re idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i am a woman babs and the only war on women i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wow you benefitted so many wins this year fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>haha green me red you now loser whos winning ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Insult                                            Comment\n",
       "0       0                  like this if you are a tribe fan \n",
       "1       1                                      you re idiot \n",
       "2       1   i am a woman babs and the only war on women i...\n",
       "3       1   wow you benefitted so many wins this year fro...\n",
       "4       1   haha green me red you now loser whos winning ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning for both train and test set has completed successfully. It's time for the feature extraction part, while training the different models (NB, SVM, RF) and seeing what benchmarks we can actually achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we are going to try Naive Bayes classifier without any improvement. Specifically, using CountVectorizer (aka Bag of Words) we are going to extract features and train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to mention that the effectiveness of our models wlll be evaluated only in the test set, inspecting accuracy and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df['Comment'])\n",
    "y_train = train_df['Insult']\n",
    "X_test = vectorizer.transform(test_df['Comment'])\n",
    "y_test = test_df['Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6676\n",
      "F1-score: 0.6664\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first improvement, lemmatization is going to be applied in both training and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lem_sentence = []\n",
    "    token_words = word_tokenize(text)\n",
    "    lem_sentence = [lemmatizer.lemmatize(word) for word in token_words]\n",
    "    text = \" \".join(lem_sentence)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments_1 = train_df['Comment'].apply(lambda x: lemmatize(x))\n",
    "test_comments_1 = test_df['Comment'].apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BoW features once again, but now using lemmatized comments\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_comments_1)\n",
    "X_test = vectorizer.transform(test_comments_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6711\n",
      "F1-score: 0.6708\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a second improvement, we are going to remove stop words. Take notice that each improvement will be applied in the previous one and not on the naive text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopwords(text):\n",
    "    removed = remove_stopwords(text)\n",
    "    text = \"\".join(removed)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments_2 = train_comments_1.apply(lambda x: lemmatize(x))\n",
    "test_comments_2 = test_comments_1.apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract BoW features once again, but now using lemmatized and without stop words comments\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_comments_2)\n",
    "X_test = vectorizer.transform(test_comments_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6698\n",
      "F1-score: 0.6702\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a third improvement, we are going to use bigrams in our BoW feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(train_comments_2)\n",
    "X_test = vectorizer.transform(test_comments_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6738\n",
      "F1-score: 0.6279\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate model\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Laplace Smoothing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smoothing priors α >= 0 accounts for features not present in the learning samples and prevents zero probabilities in further computations. Setting α = 1 is called Laplace smoothing, while α < 1 is called Lidstone smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6550\n",
      "F1-score: 0.5190\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF + Part-of-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to extract a more sophisticated feature vector. For this tf-idf vectorizer will be used along Part-of-Speech Based Features, provided by NLTK functionalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this expirement, we are going to train and evalute a SVM as well as a Random Decision Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tf-idf vectorizer and extract features from the train set\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "train_tfidf_vec = tfidf_vectorizer.fit_transform(train_df['Comment'])\n",
    "train_tfidf_data = pd.DataFrame(train_tfidf_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tf-idf based features from the test set\n",
    "test_tfidf_vec = tfidf_vectorizer.transform(test_df['Comment'])\n",
    "test_tfidf_data = pd.DataFrame(test_tfidf_vec.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the part-of-speech tagger provided by the NTLK, tag each word in each comment with the part of its speech (noun, verb, adverb or adjective). Then, the percentage of specific tags for each text will be calculated. That is, the frequency of each POS tag in each sample, calculated in terms of the total number of words in the sample. This way we  will have 4 new features in each text, fractionAdverbs, fractionVerbs, fractionAdjectives, fractionNouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fractions(text, pos_tag):\n",
    "    token_words = word_tokenize(text)\n",
    "    tagged_token_words = nltk.pos_tag(token_words)\n",
    "    count = sum([1 for _, tag in tagged_token_words if tag == pos_tag])\n",
    "    return round(count/(len(text)), 3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adverbs fraction\n",
    "train_df['fractionAdverbs'] = train_df['Comment'].apply(lambda x: count_fractions(x, 'RB'))\n",
    "test_df['fractionAdverbs'] = test_df['Comment'].apply(lambda x: count_fractions(x, 'RB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate verbs fraction\n",
    "train_df['fractionVerbs'] = train_df['Comment'].apply(lambda x: count_fractions(x, 'VB'))\n",
    "test_df['fractionVerbs'] = test_df['Comment'].apply(lambda x: count_fractions(x, 'VB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate adjectives fraction\n",
    "train_df['fractionAdjectives'] = train_df['Comment'].apply(lambda x: count_fractions(x, 'JJ'))\n",
    "test_df['fractionAdjectives'] = test_df['Comment'].apply(lambda x: count_fractions(x, 'JJ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate nouns fraction\n",
    "train_df['fractionNouns'] = train_df['Comment'].apply(lambda x: count_fractions(x, 'NN'))\n",
    "test_df['fractionNouns'] = test_df['Comment'].apply(lambda x: count_fractions(x, 'NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractionAdverbs</th>\n",
       "      <th>fractionVerbs</th>\n",
       "      <th>fractionAdjectives</th>\n",
       "      <th>fractionNouns</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>92625</th>\n",
       "      <th>92626</th>\n",
       "      <th>92627</th>\n",
       "      <th>92628</th>\n",
       "      <th>92629</th>\n",
       "      <th>92630</th>\n",
       "      <th>92631</th>\n",
       "      <th>92632</th>\n",
       "      <th>92633</th>\n",
       "      <th>92634</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92639 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractionAdverbs  fractionVerbs  fractionAdjectives  fractionNouns    0  \\\n",
       "0              0.0            0.0                 0.0            5.3  0.0   \n",
       "1              1.1            1.1                 1.1            3.4  0.0   \n",
       "2              1.6            1.1                 1.4            3.0  0.0   \n",
       "3              0.7            3.4                 1.9            1.5  0.0   \n",
       "4              0.0            0.0                 4.9           20.9  0.0   \n",
       "\n",
       "     1    2    3    4    5  ...  92625  92626  92627  92628  92629  92630  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   92631  92632  92633  92634  \n",
       "0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 92639 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat features to formulate the final data for train set\n",
    "train_final_data = pd.concat([train_df['fractionAdverbs'], train_df['fractionVerbs'], \n",
    "                              train_df['fractionAdjectives'], train_df['fractionNouns'], \n",
    "                              train_tfidf_data], axis=1)\n",
    "train_final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fractionAdverbs</th>\n",
       "      <th>fractionVerbs</th>\n",
       "      <th>fractionAdjectives</th>\n",
       "      <th>fractionNouns</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>92625</th>\n",
       "      <th>92626</th>\n",
       "      <th>92627</th>\n",
       "      <th>92628</th>\n",
       "      <th>92629</th>\n",
       "      <th>92630</th>\n",
       "      <th>92631</th>\n",
       "      <th>92632</th>\n",
       "      <th>92633</th>\n",
       "      <th>92634</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92639 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fractionAdverbs  fractionVerbs  fractionAdjectives  fractionNouns    0  \\\n",
       "0              0.0            0.0                 2.9            2.9  0.0   \n",
       "1              0.0            7.1                 0.0            0.0  0.0   \n",
       "2              0.0            0.0                 2.1            3.2  0.0   \n",
       "3              1.5            0.0                 2.9            5.9  0.0   \n",
       "4              3.6            0.0                 3.6            3.6  0.0   \n",
       "\n",
       "     1    2    3    4    5  ...  92625  92626  92627  92628  92629  92630  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "   92631  92632  92633  92634  \n",
       "0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 92639 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat features to formulate the final data for test set\n",
    "test_final_data = pd.concat([test_df['fractionAdverbs'], test_df['fractionVerbs'], \n",
    "                             test_df['fractionAdjectives'], test_df['fractionNouns'], \n",
    "                             test_tfidf_data], axis=1)\n",
    "test_final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(gamma='auto')\n",
    "clf.fit(train_final_data, y_train)\n",
    "y_pred = clf.predict(test_final_data)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(train_final_data, y_train)\n",
    "y_pred = clf.predict(test_final_data)\n",
    "print(\"Accuracy score: {:.4f}\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"F1-score: {:.4f}\".format(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
